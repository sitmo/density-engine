python scripts/train.py --layers 32 --components 32 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 64 --components 32 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 128 --components 32 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 256 --components 32 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw

python scripts/train.py --layers 32 --components 64 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 64 --components 64 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 128 --components 64 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 256 --components 64 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw

python scripts/train.py --layers 32 --components 128 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 64 --components 128 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 128 --components 128 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 256 --components 128 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw

python scripts/train.py --layers 32 --components 256 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 64 --components 256 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 128 --components 256 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
python scripts/train.py --layers 256 --components 256 --activation gelu --batch-size=256 --lr-max 0.1  --samples 20_000_000 --warmup-samples 100_000 --scheduler power --power-scale 100_000 --power-alpha -1.2  --cooldown-samples 2_000_000   --optimizer adamw
